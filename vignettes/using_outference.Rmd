---
title: "Using Outference Package"
author: "Shuxiao Chen"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Using Outference Package}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
This vignette illustrates the usage of `outference` package, which is a tool for doing valid statistical inference corrected for outlier removal in linear regressions. We refer the reader to *OUR PAPER* for technical details.

## The Main Function
The main function in this package is `outference`, which is written in a similar fashion as the `lm` function and returns an object of S3 class `outference`. This function detects outliers using a user-specified method, and fits a linear regression model with outliers removed. Common generic functions for the `lm` object are overwritten to extract useful inferential results from the `outference` object.

## A Synthetic Example
We illustrate the package using a synthetic example. 

### Generating the Data
We generate the data from a "mean-shift model". That is, we first generate responses from a classical linear model, and then shift several responses, who are considered as outliers.
```{r}
set.seed(2667)
n <- 100; p <- 6
# generate the design matrix
X <- matrix(rnorm(n*(p-1)), n, (p-1))
X <- scale(X, FALSE, TRUE)*sqrt(n/(n-1)) # col of X and has norm sqrt(n)
my.data <- as.data.frame(X)
X <- cbind(rep(1, n), X)
# generate the response with noise i.i.d. from N(0, 1)
beta <- rnorm(p)
y <- X %*% beta + rnorm(n)
# assume the first five observations are outliers, shifed upwards by 5 units
y[1:5] <- y[1:5] + 5
# format the dataset
my.data <- cbind(y = y, my.data)
head(my.data)
```

### Fitting the Model
We then detect the outliers in the synthetic data. For illustration purposes, we use the classical Cook's distance, and claim an observation is an outlier if its cook's distance is greater than $4/n$. Our method accommodates both cases when the noise level $\sigma$ is known or unknown. In the $\sigma$ known case, our method is the generalization of classical $z$-test (testing the regression coefficients) and $\chi^2$-test (tesing for group structures or "nested models"), as well as the classical $z$-intervals (for regression coefficients).  When $\sigma$ is unknown, we can either plug in an estimate of $\sigma$, or we resort to the generalization of classical $t$-test (testing the regression coefficients) and $F$-test (tesing for group structures or "nested models"). For now our method does not provide the corresponding generalization of $t$-intervals. In this vignette, we will focus on the case where $\sigma$ is estimated. 
```{r}
library(outference)
fit <- outference(y ~ ., data = my.data, method = "cook", cutoff = 4, sigma = "estimate")
fit
```
Notice that the syntax and the output are very similar to those of the `lm` function. 

### Extracting the Information
To visualize how the outliers are detected, we can plot the Cook's distance for each observation.
```{r, fig.width = 6, fig.height = 4}
plot(fit)
```

We see that the first five observations are successfully detected, while the 42-nd observation is a false alarm. As usual, we can use the `coef` function to extract the regression coefficients in the model with detected outliers removed.
```{r}
coef(fit)
```

To test the significance of regression coefficients and to test for the "global null" (i.e. test if the model only consists of the intercept), we use the `summary` function. Again notice the similarity of the output with that of `summary.lm`. 
```{r}
summary(fit)
```

One calls the `confint` function to extract the confidence intervals for each coefficient.
```{r}
confint(fit, level = 0.95)
```

One uses the `predict` function to extract confidence intervals for the regression surfaces, as well as the prediction intervals.
```{r}
# new data points for prediction
new.data <- t(rnorm(p-1))
colnames(new.data) <- colnames(my.data)[-1]
new.data <- as.data.frame(new.data)
predict(fit, newdata = new.data, interval = "confidence", level = 0.95)
predict(fit, newdata = new.data, interval = "prediction", level = 0.95)
```

## Other Exported Functions
Apart from the `outference` function, there are two other functions that are also exported: `coeftest` and `grptest`. Those two functions are internally called by the `summary` function, and they correspond to testing for regression coefficients and testing the group structures. The aim for exporting those two questions is to allow more flexibility for experienced users (since users can access to more information from the output of those two functions).
```{r}
coeftest(fit, index = 2) # test the significance of "V1"
grptest(fit, group = 2:3) # test if "V1" and "V2" are simultaneously zero
```

